{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80a1dfb-df6c-40de-b2dc-cac38dbb5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.What is a parameter?\n",
    "'''\n",
    "A parameter is a value or coefficient in a model that the algorithm learns from data.\n",
    "\n",
    "Use case: In linear regression y = mx + b, m and b are parameters.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d58b2-a02f-4541-8e0c-b36aab99ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.What is correlation?\n",
    "'''\n",
    "Correlation measures the strength and direction of a linear relationship between two variables.\n",
    "\n",
    "Use case: Check if advertising spend and sales are related.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72b28f-254f-4482-9515-23d3fc242127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 a).What does negative correlation mean?\n",
    "'''\n",
    "Negative correlation implies that as one variable increases, the other decreases.\n",
    "\n",
    "Use case: More absenteeism → lower productivity.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632a174e-fbe6-43e2-b40f-457e087f7594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Define Machine Learning. Main components?\n",
    "'''\n",
    "Definition: Machine Learning is a subset of AI where algorithms learn patterns from data to make predictions or decisions.\n",
    "\n",
    "Components:\n",
    "\n",
    "Data: Training/testing datasets.\n",
    "\n",
    "Features: Input variables.\n",
    "\n",
    "Model: Algorithm learning patterns.\n",
    "\n",
    "Loss Function: Measures error.\n",
    "\n",
    "Optimizer: Updates model to reduce error.\n",
    "\n",
    "Use case: Predicting house prices using historical data.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b501cfe-9a0e-4eb3-ac22-79c16b4e1b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.How does loss value help in determining model quality?\n",
    "'''\n",
    "Loss quantifies difference between predicted and actual values.\n",
    "\n",
    "Lower loss → better model fit.\n",
    "\n",
    "Use case: MSE in regression indicates prediction accuracy.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a60f94-1702-40ac-b2e9-12f407cdfc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.What are continuous and categorical variables?\n",
    "'''\n",
    "Continuous: Numeric variables with infinite values. (e.g., temperature, salary)\n",
    "\n",
    "Categorical: Variables with discrete categories. (e.g., gender, country)\n",
    "\n",
    "Use case: Continuous → regression; Categorical → classification.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b38f7-8015-4889-9ba7-f3a0ae404694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Handling categorical variables in ML (techniques)?\n",
    "'''\n",
    "Label Encoding: Convert categories to numbers.\n",
    "\n",
    "One-Hot Encoding: Binary vector for each category.\n",
    "\n",
    "Use case: Gender or country in predictive models.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85d3e71-25da-4887-a67d-557010fd6243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.Training vs testing dataset\n",
    "'''\n",
    "Training set: Used to learn parameters from data (fit the model).\n",
    "\n",
    "Testing set: Held out for final performance estimate on unseen data.\n",
    "\n",
    "Use case: Fraud model trains on past labeled transactions; test set estimates real-world detection performance\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfdc09d-2708-41f6-b5c6-ff692639ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.what is Test set\n",
    "'''\n",
    "Meaning: The portion of data not used in fitting, used to evaluate generalization.\n",
    "\n",
    "Use case: Report accuracy/RMSE on the test set to communicate expected performance on new data.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae4b7b-2b78-499e-859c-e5397be9a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.How do we split data for model fitting (training and testing) in Python?\n",
    "'''\n",
    "We use train_test_split() from sklearn.model_selection to divide features (X) and target (y) into X_train, X_test, y_train, y_test for \n",
    "training and evaluation.\n",
    "Standard split (most common)\n",
    "Steps: Separate X (features) and y (label) → call train_test_split.\n",
    "Use case: Train a model on 80% data and evaluate on 20% unseen data to estimate generalization\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c29db-46a6-4b09-a806-ec7b4ef9664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.how do you approach to a Machine Learning Problem\n",
    "'''\n",
    "Define the Objective\n",
    "\n",
    "Clearly state what you want to predict or classify.\n",
    "\n",
    "Example: Predict customer churn for a telecom company.\n",
    "\n",
    "Collect Data\n",
    "\n",
    "Gather relevant, high-quality data from databases, APIs, or sensors.\n",
    "\n",
    "Example: Customer demographics, service usage, complaints.\n",
    "\n",
    "Understand & Explore Data (EDA)\n",
    "\n",
    "Analyze distributions, patterns, missing values, outliers.\n",
    "\n",
    "Tools: Histograms, boxplots, correlation matrices.\n",
    "\n",
    "Use case: Identify which features influence churn.\n",
    "\n",
    "Preprocess Data\n",
    "\n",
    "Handle missing values, normalize/scale numerical features, encode categorical variables.\n",
    "\n",
    "Use case: One-Hot Encoding for categorical variables like “Gender” or “Region”.\n",
    "\n",
    "Split Data\n",
    "\n",
    "Divide dataset into training and testing sets (e.g., 80:20).\n",
    "\n",
    "Use case: Train model on known data and evaluate on unseen data.\n",
    "\n",
    "Choose a Model\n",
    "\n",
    "Select an algorithm based on problem type (regression, classification, clustering).\n",
    "\n",
    "Example: Logistic Regression for churn prediction; Random Forest for complex patterns.\n",
    "\n",
    "Train the Model\n",
    "\n",
    "Fit the model on training data using model.fit().\n",
    "\n",
    "Use case: Learn patterns between features and target variable.\n",
    "\n",
    "Evaluate the Model\n",
    "\n",
    "Use metrics like accuracy, precision, recall, F1-score, RMSE depending on problem type.\n",
    "\n",
    "Use case: Evaluate whether churn predictions are reliable.\n",
    "\n",
    "Hyperparameter Tuning\n",
    "\n",
    "Optimize model performance using Grid Search, Random Search, or Bayesian Optimization.\n",
    "\n",
    "Example: Adjust learning rate, tree depth, or number of estimators.\n",
    "\n",
    "Validate & Test\n",
    "\n",
    "Confirm performance on unseen test data to avoid overfitting.\n",
    "\n",
    "Use case: Ensure model generalizes well to new customers.\n",
    "\n",
    "Deploy & Monitor\n",
    "\n",
    "Integrate model into production and continuously monitor performance.\n",
    "\n",
    "Use case: Update churn prediction model with new customer data monthly.\n",
    "\n",
    "Iterate\n",
    "\n",
    "Refine steps based on results; feature engineering, more data, or better models.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6b865-92d9-4609-8264-d1fa5b6eb7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.Why do we have to perform EDA before fitting a model to the data?\n",
    "'''\n",
    "Purpose: EDA reveals missing values, outliers, leakage, skew, imbalance, and feature relationships that affect model choice and \n",
    "preprocessing.\n",
    "\n",
    "Use case: Detect target leakage (e.g., a feature created using future info) before training inflates performance unrealistically\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a4a7d-d63b-46c7-b804-f8a2773f2642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.What is correlation?\n",
    "'''\n",
    "Correlation measures the strength and direction of a linear relationship between two variables.\n",
    "\n",
    "Use case: Check if advertising spend and sales are related.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f50e9c-e86f-4d98-a82e-6fac2294bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.What does negative correlation mean?\n",
    "'''\n",
    "Meaning:\n",
    "\n",
    "r<0 indicates inverse movement; perfect negative correlation is -1.\n",
    "\n",
    "Use case: If “price” and “demand” show negative correlation, higher price tends to align with lower demand (useful for pricing insights).\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e578e-f7f0-4922-ae1c-f690b81fc46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.How can you find correlation between variables in Python?\n",
    "'''\n",
    "Compute correlation between variables in Python using pandas.DataFrame.corr() for pairwise correlation matrices or \n",
    "numpy.corrcoef() for specific pairs.\n",
    "\n",
    "Pandas (most common for DataFrames)\n",
    "Method: df.corr(method='pearson') returns correlation matrix for all numeric columns.\n",
    "Use case: Check multicollinearity in EDA; drop features with |corr| > 0.9 between predictors\n",
    "\n",
    "import pandas as pd\n",
    "corr_matrix = df.corr()  # Pearson by default\n",
    "print(df[['price', 'size']].corr())  # Specific pair\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1333ef-9f10-4c63-9621-11d0c632da00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#15.What is causation? Explain difference between correlation and causation with an example.\n",
    "'''\n",
    "Causation occurs when changing one variable directly causes a change in another.\n",
    "\n",
    "Correlation vs Causation\n",
    "Correlation: Statistical association between variables (they change together); range -1 to +1; no directionality implied.\n",
    "\n",
    "Causation: One variable (cause) produces change in another (effect); requires temporal order and experimental evidence.\n",
    "Key difference: Correlation exists without causation; causation always produces correlation.\n",
    "\n",
    "Classic Example\n",
    "Ice cream sales vs shark attacks (summer months):\n",
    "\n",
    "Observed: Strong positive correlation (both rise together).\n",
    "\n",
    "Reality: No causation—temperature (third variable) drives both. Hot weather → more beachgoers → more ice cream sales AND shark encounters.\n",
    "Use case: Marketers must distinguish; correlation alone cannot justify \"ice cream prevents shark attacks\" advertising.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6387fc87-f90a-46ee-b773-933d8d36b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16.What is an Optimizer? What are different types of optimizers? Explain each with an example?\n",
    "\n",
    "'''\n",
    "Optimizer\n",
    "\n",
    "Definition: An optimizer is an algorithm used to update model parameters (weights and biases) to minimize the loss function during training.\n",
    "\n",
    "Purpose: Helps the model learn efficiently and converge to the best solution.\n",
    "\n",
    "Use case: In neural networks, optimizers adjust weights so predicted outputs are closer to actual outputs.\n",
    "\n",
    "Types of Optimizers\n",
    "\n",
    "Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Updates weights after each training example.\n",
    "\n",
    "Pros: Simple, effective for large datasets.\n",
    "\n",
    "Cons: Can be slow; may oscillate near minima.\n",
    "\n",
    "Example: Updating weights in a linear regression model with large data batch by batch.\n",
    "\n",
    "Momentum\n",
    "\n",
    "Adds momentum term to SGD to accelerate convergence.\n",
    "\n",
    "Reduces oscillations and speeds up learning in valleys of the loss surface.\n",
    "\n",
    "Example: Training deep neural networks with steep and flat regions in loss landscape.\n",
    "\n",
    "RMSProp\n",
    "\n",
    "Adaptive learning rate optimizer; adjusts step size for each parameter.\n",
    "\n",
    "Good for non-stationary or sparse data.\n",
    "\n",
    "Example: Training recurrent neural networks (RNNs) for time series predictions.\n",
    "\n",
    "Adam (Adaptive Moment Estimation)\n",
    "\n",
    "Combines Momentum + RMSProp for adaptive learning rate.\n",
    "\n",
    "Fast convergence, widely used in deep learning.\n",
    "\n",
    "Example: Training convolutional neural networks (CNNs) for image classification.\n",
    "\n",
    "Adagrad\n",
    "\n",
    "Adjusts learning rate for each parameter based on past gradients.\n",
    "\n",
    "Works well for sparse data but may decay learning rate too fast.\n",
    "\n",
    "Example: Natural language processing with sparse word embeddings.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4213cce-efdf-45c9-88f8-8d86eddf576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17.What is sklearn.linear_model ?\n",
    "'''\n",
    "Definition:\n",
    "sklearn.linear_model is a module in Scikit-learn that contains linear models for regression and classification tasks.\n",
    "\n",
    "Purpose:\n",
    "Provides pre-built classes and functions to fit linear relationships between input features (X) and target variable (y).\n",
    "\n",
    "Key Models in sklearn.linear_model:\n",
    "\n",
    "LinearRegression – Predicts continuous target values (regression).\n",
    "\n",
    "Example: Predict house prices based on size and location.\n",
    "\n",
    "LogisticRegression – Predicts categorical target (classification).\n",
    "\n",
    "Example: Predict whether a customer will churn (yes/no).\n",
    "\n",
    "Ridge – Linear regression with L2 regularization to reduce overfitting.\n",
    "\n",
    "Lasso – Linear regression with L1 regularization for feature selection.\n",
    "\n",
    "ElasticNet – Combines L1 and L2 regularization.\n",
    "\n",
    "Use case:\n",
    "Quickly implement regression or classification models with minimal coding and built-in support for fitting, predicting, and evaluating.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c085c25d-1b4a-4c83-b67f-b97826d33a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18.What does model.fit() do? What arguments must be given?\n",
    "'''\n",
    "model.fit()\n",
    "\n",
    "Definition:\n",
    "model.fit() is a method in Scikit-learn used to train a machine learning model on a given dataset.\n",
    "\n",
    "Function: The model learns patterns from the input features (X) and target variable (y) by adjusting its internal parameters.\n",
    "\n",
    "Arguments\n",
    "\n",
    "X – Features/input variables (can be a NumPy array, Pandas DataFrame, or sparse matrix).\n",
    "\n",
    "y – Target/output variable (labels for supervised learning).\n",
    "\n",
    "Optional arguments (depending on model):\n",
    "\n",
    "sample_weight – Assigns weights to training samples.\n",
    "\n",
    "epochs or batch_size – In neural networks (via other libraries like Keras).\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3892297-2739-4330-b61b-bc3cfda923c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19.What does model.predict() do? What arguments must be given?\n",
    "'''\n",
    "Definition:\n",
    "model.predict() is a method in Scikit-learn used to generate predictions from a trained machine learning model.\n",
    "\n",
    "Function: Uses the learned parameters from model.fit() to produce output values for new or unseen data.\n",
    "\n",
    "Arguments\n",
    "\n",
    "X – Features/input variables for which predictions are required.\n",
    "\n",
    "Must have same number of columns and preprocessing as the training data.\n",
    "\n",
    "Optional arguments (rare, depending on model):\n",
    "\n",
    "For some models, you can provide sample weights or return confidence scores.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ca5c5-5b37-45b7-afb1-1242174dcee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20.What are continuous and categorical variables?\n",
    "'''\n",
    "Continuous variables take any value within a range (measurable); categorical variables represent distinct groups/labels (descriptive).\n",
    "\n",
    "Continuous Variables\n",
    "Definition: Numeric values on a continuum; infinite possible values (including decimals).\n",
    "\n",
    "Use case: Height (170.5 cm), temperature (23.7°C) → suitable for regression models.\n",
    "\n",
    "Categorical Variables\n",
    "Definition: Non-numeric labels or groups; finite distinct categories.\n",
    "\n",
    "Types:\n",
    "Nominal: No order (colors, cities).\n",
    "\n",
    "Ordinal: Ordered categories (low/medium/high).\n",
    "Use case: \"City\" (nominal) → one-hot encoding; \"Education level\" (ordinal) → ordinal encoding.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990708d-75be-402a-ae2b-0971b72644df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21.What is feature scaling? How does it help in Machine Learning?\n",
    "'''\n",
    "Feature Scaling\n",
    "\n",
    "Definition:\n",
    "\n",
    "Feature scaling is the process of transforming input features to a similar range so that no single feature dominates due to its magnitude.\n",
    "\n",
    "Purpose in Machine Learning:\n",
    "\n",
    "Ensures all features contribute equally to model training.\n",
    "\n",
    "Improves convergence speed for gradient-based algorithms (e.g., linear regression, neural networks).\n",
    "\n",
    "Prevents bias toward features with larger values in distance-based algorithms (e.g., KNN, SVM, clustering).\n",
    "\n",
    "Common Techniques:\n",
    "\n",
    "Min-Max Scaling (Normalization): Scales features to [0,1] range.\n",
    "\n",
    "Formula: X_scaled = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "Use case: Image pixel values (0–255 → 0–1).\n",
    "\n",
    "Standardization (Z-score): Centers data around 0 with unit variance.\n",
    "\n",
    "Formula: X_scaled = (X - mean) / standard deviation\n",
    "\n",
    "Use case: Regression or neural networks where zero-centered data helps convergence.\n",
    "\n",
    "Use Case Examples:\n",
    "\n",
    "K-Nearest Neighbors: Distances between features determine predictions → unscaled features distort distances.\n",
    "\n",
    "Gradient Descent Models: Faster convergence when features are scaled.\n",
    "\n",
    "SVM & PCA: Feature scale affects margins and variance capture.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a82b8-6ffc-49b0-a211-763e362b7125",
   "metadata": {},
   "outputs": [],
   "source": [
    "#22.How do we perform scaling in Python?\n",
    "'''\n",
    "We perform feature scaling in Python using sklearn.preprocessing scalers to normalize numeric features for ML algorithms.\n",
    "\n",
    "StandardScaler (Z-score normalization)\n",
    "Method: (X - mean) / std; results in mean=0, std=1.\n",
    "Use case: Gradient descent models (logistic regression, SVM) where equal feature variance is needed.\n",
    "\n",
    "\n",
    "# python code \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)  # Fit on train only\n",
    "X_test_scaled = scaler.transform(X_test)  # Transform test\n",
    "MinMaxScaler (0-1 normalization)\n",
    "\n",
    "Method: (X - min) / (max - min); bounds data to.\n",
    "\n",
    "Use case: Neural networks, KNN where fixed range is preferred.\n",
    "python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "RobustScaler (median-based)\n",
    "Method: (X - median) / IQR; robust to outliers.\n",
    "\n",
    "Use case: Datasets with extreme outliers (financial data, sensor readings).\n",
    "\n",
    "Pipeline Integration\n",
    "python\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([('scaler', StandardScaler()), ('model', LogisticRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f3e98-4340-485e-bf56-6be848d0d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23.What is sklearn.preprocessing?\n",
    "'''\n",
    "sklearn.preprocessing\n",
    "\n",
    "Definition:\n",
    "sklearn.preprocessing is a module in Scikit-learn that provides tools to prepare and transform data for machine learning.\n",
    "\n",
    "Purpose:\n",
    "\n",
    "Scale or normalize features.\n",
    "\n",
    "Encode categorical variables into numeric formats.\n",
    "\n",
    "Handle missing values or outliers (indirectly via transformers).\n",
    "\n",
    "Make data ready for model training and improve algorithm performance.\n",
    "\n",
    "Common Classes/Functions:\n",
    "\n",
    "StandardScaler – Standardizes features (mean=0, std=1).\n",
    "\n",
    "MinMaxScaler – Scales features to a fixed range (0–1).\n",
    "\n",
    "RobustScaler – Scales features using median & IQR, robust to outliers.\n",
    "\n",
    "LabelEncoder – Converts categorical labels to numbers.\n",
    "\n",
    "OneHotEncoder – Converts categorical features into binary vectors.\n",
    "\n",
    "PolynomialFeatures – Generates polynomial features for regression.\n",
    "\n",
    "Use Case Examples:\n",
    "\n",
    "Neural networks → StandardScaler for faster convergence.\n",
    "\n",
    "KNN or SVM → MinMaxScaler to normalize distances.\n",
    "\n",
    "Logistic regression with categorical data → OneHotEncoder for feature representation.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d724a-6a8c-4ac2-a2c1-f97a93add4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#24.How do we split data for model fitting (training and testing) in Python?\n",
    "'''\n",
    "Splitting Data for Model Fitting in Python\n",
    "\n",
    "Definition:\n",
    "Splitting data divides the dataset into training and testing sets.\n",
    "\n",
    "Training set: Used to train the model (learn patterns).\n",
    "\n",
    "Testing set: Used to evaluate model performance on unseen data.\n",
    "\n",
    "How to Split Data Using scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = features, y = target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,    # 20% test, 80% train\n",
    "    random_state=42,  # Ensures reproducibility\n",
    "    shuffle=True      # Randomly shuffles data before splitting\n",
    ")\n",
    "\n",
    "Parameters Explained\n",
    "\n",
    "X – Input features (DataFrame/array).\n",
    "\n",
    "y – Target variable (labels).\n",
    "\n",
    "test_size – Fraction of data for testing (e.g., 0.2 = 20%).\n",
    "\n",
    "train_size – Optional; fraction for training if you want to specify both.\n",
    "\n",
    "random_state – Ensures the split is reproducible.\n",
    "\n",
    "shuffle – Shuffles data before splitting (default: True).\n",
    "\n",
    "Use Case Example\n",
    "\n",
    "Predicting house prices:\n",
    "\n",
    "X_train, y_train: Model learns relationship between features (size, location) and price.\n",
    "\n",
    "X_test, y_test: Check how accurately the model predicts prices for unseen houses.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7eb04-5ead-4e40-9293-e5ba2219e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#25.Explain data encoding?\n",
    "'''\n",
    "Data encoding converts categorical (non-numeric) data into numerical format for machine learning algorithms.\n",
    "\n",
    "One-Hot Encoding\n",
    "Method: Creates binary columns per category (1 if present, 0 otherwise).\n",
    "\n",
    "Use case: Nominal data like \"City\" (Mumbai→, Delhi→); prevents ordinal assumptions in linear models.\n",
    "\n",
    "Label Encoding\n",
    "Method: Maps each category to unique integer (A=0, B=1, C=2).\n",
    "\n",
    "Use case: Tree-based models (RandomForest) where numeric labels don't imply false order.\n",
    "\n",
    "Ordinal Encoding\n",
    "Method: Maps ordered categories to integers (Low=0, Medium=1, High=2).\n",
    "Use case: Ratings (Poor/Fair/Good) where natural order exist\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
