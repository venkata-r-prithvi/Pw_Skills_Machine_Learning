{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33c84d9-7517-4cb3-a075-20369162ef40",
   "metadata": {},
   "source": [
    "#1 Simple Linear Regression (SLR)\n",
    "\n",
    "1. Definition\n",
    "\n",
    "    Simple Linear Regression is a statistical technique used to study the relationship between one independent variable (X) and one dependent variable (Y).\n",
    "    It assumes a linear relationship between the two variables.\n",
    "\n",
    "2. Mathematical Form\n",
    "\n",
    "   The model is expressed as:\n",
    "\n",
    "     Y = β₀ + β₁X + ε\n",
    "\n",
    "   (β₀): Intercept (value of Y when X = 0)\n",
    "\n",
    "   (β₁): Slope (change in Y for a one-unit change in X)\n",
    "\n",
    "   (ε): Random error term\n",
    "\n",
    "3. Purpose of SLR\n",
    "\n",
    "   To Measure Relationship: Determines the direction and strength of the linear association between X and Y.\n",
    "   To Estimate Impact: Quantifies how much Y changes when X changes.\n",
    "   To Make Predictions: Uses the fitted regression equation to predict values of Y for given values of X.\n",
    "   To Test Significance: Helps assess whether the relationship between variables is statistically significant.\n",
    "\n",
    "4. Applications\n",
    "\n",
    "   Used in economics, business, social sciences, and scientific research for analyzing trends and supporting data-driven decisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192f9da-5526-4fdf-8d6e-0111489bdbae",
   "metadata": {},
   "source": [
    "#2.Simple Linear Regression is based on the following key assumptions:\n",
    "\n",
    "1. Linearity\n",
    "\n",
    "   There exists a linear relationship between the independent variable (X) and the dependent variable (Y).\n",
    "   The expected value of Y is a linear function of X.\n",
    "\n",
    "2. Independence of Errors\n",
    "\n",
    "   The residuals (error terms) are independent of each other.\n",
    "   The error for one observation does not influence the error for another.\n",
    "\n",
    "3. Homoscedasticity (Constant Variance)\n",
    "\n",
    "   The variance of the error terms remains constant across all levels of the independent variable.\n",
    "   In other words, the spread of residuals is the same for all predicted values.\n",
    "\n",
    "4. Normality of Errors\n",
    "\n",
    "   The error terms are normally distributed.\n",
    "   This assumption is particularly important for hypothesis testing and confidence interval estimation.\n",
    "\n",
    "5. No Perfect Multicollinearity\n",
    "\n",
    "   In Simple Linear Regression, there is only one independent variable, so perfect multicollinearity is not applicable.\n",
    "   However, the independent variable should exhibit variation (it should not be constant).\n",
    "\n",
    "These assumptions ensure that the estimators obtained through the method of least squares are unbiased, efficient, and suitable for statistical inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247fb543-376e-4b78-9be7-72a754264544",
   "metadata": {},
   "source": [
    "#3.The mathematical equation for a Simple Linear Regression (SLR) model is:\n",
    "\n",
    "Mathematical Form\n",
    "\n",
    "   The model is expressed as:\n",
    "\n",
    "     Y = β₀ + β₁X + ε\n",
    "\n",
    "   (β₀): Intercept (value of Y when X = 0)\n",
    "\n",
    "   (β₁): Slope (change in Y for a one-unit change in X)\n",
    "\n",
    "   (ε): Random error term\n",
    "\n",
    "Explanation of each term:\n",
    "\n",
    "1. (Yi) (Dependent Variable)\n",
    "\n",
    "   Represents the observed value of the response variable for the ith observation.\n",
    "   It is the variable we aim to explain or predict.\n",
    "\n",
    "2. (Xi) (Independent Variable)\n",
    "\n",
    "   Represents the value of the predictor variable for the ith observation.\n",
    "   It is the variable used to explain changes in the dependent variable.\n",
    "\n",
    "3. (β₀) (Intercept)\n",
    "\n",
    "   The expected value of (Y) when (X = 0).\n",
    "   It indicates where the regression line crosses the Y-axis.\n",
    "\n",
    "4. (β1) (Slope Coefficient)\n",
    "\n",
    "   Represents the change in the expected value of (Y) for a one-unit increase in (X).\n",
    "   It indicates the direction (positive or negative) and strength of the linear relationship.\n",
    "\n",
    "5. (ε) (Error Term)\n",
    "\n",
    "   Captures the difference between the observed value (Yi) and the predicted value.\n",
    "   It accounts for other factors affecting (Y) that are not included in the model.\n",
    "\n",
    "Thus, the equation expresses the dependent variable as a linear function of the independent variable plus a random error component.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7999133-84c6-46fc-b260-fb7da88edd13",
   "metadata": {},
   "source": [
    "#4 One common real-world application of Simple Linear Regression is in predicting house prices.\n",
    "\n",
    "Example: House Price Prediction\n",
    "\n",
    "Suppose a real estate analyst wants to estimate the price of a house based on its size (measured in square feet).\n",
    "\n",
    " Dependent Variable (Y): House price\n",
    " Independent Variable (X): Size of the house in square feet\n",
    "\n",
    "The analyst collects data from recently sold houses and fits a simple linear regression model:\n",
    "\n",
    "Price = β₀ + β₁(Size) + ε\n",
    "\n",
    "Interpretation:\n",
    "\n",
    " The intercept (β₀) represents the estimated base price when the size is zero (theoretical starting value).\n",
    " The slope (β₁) represents how much the price is expected to increase for each additional square foot.\n",
    " The error term (ε) accounts for other factors affecting price, such as location, number of bedrooms, age of the property, and market conditions.\n",
    "\n",
    "Purpose:\n",
    "\n",
    "The model helps understand the relationship between house size and price and allows the analyst to predict the expected price of a house given its size.\n",
    "\n",
    "This example illustrates how Simple Linear Regression can be used in business and economic decision-making to estimate outcomes based on a single predictor variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b401aa74-642c-4d84-b979-e5cdba6808fb",
   "metadata": {},
   "source": [
    "#5 The method of least squares is a mathematical technique used in linear regression to estimate the best-fitting line through a set of data points.\n",
    "\n",
    "In Simple Linear Regression, the objective is to determine the values of the intercept (β₀) and slope (β₁) that produce the line which best represents the relationship between the independent variable (X) and the dependent variable (Y).\n",
    "\n",
    "Each observation has a residual (error), defined as:\n",
    "\n",
    "Residual = Actual value − Predicted value\n",
    "\n",
    "The method of least squares follows these steps:\n",
    "\n",
    "1. Compute the residual for each observation.\n",
    "2. Square each residual to eliminate negative signs and assign greater weight to larger errors.\n",
    "3. Sum all the squared residuals.\n",
    "4. Select the values of β₀ and β₁ that minimize this total sum.\n",
    "\n",
    "Mathematically, the method minimizes:\n",
    "\n",
    "∑ (Yᵢ − Ŷᵢ)²\n",
    "\n",
    "where\n",
    "Yᵢ = observed value\n",
    "Ŷᵢ = predicted value\n",
    "\n",
    "Thus, the method of least squares determines the regression line that minimizes the total squared prediction error, providing the best linear fit to the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e37ad-8804-45a2-a779-b65a32071ee7",
   "metadata": {},
   "source": [
    "#6.Logistic Regression is a statistical classification technique used to model the probability of a binary outcome based on one or more independent variables. The dependent variable in logistic regression is categorical, typically taking values such as 0 and 1 (for example, pass/fail, yes/no, disease/no disease).\n",
    "\n",
    "Instead of predicting a continuous value, logistic regression predicts the probability that an observation belongs to a particular class. It uses the logistic (sigmoid) function to transform a linear combination of predictors into a value between 0 and 1:\n",
    "\n",
    "p = 1 / (1 + e^-(β₀ + β₁X))\n",
    "\n",
    "Where:\n",
    "\n",
    "p = probability of the event occurring\n",
    "β₀ = intercept\n",
    "β₁ = coefficient of the independent variable\n",
    "X = independent variable\n",
    "\n",
    "Differences between Logistic Regression and Linear Regression:\n",
    "\n",
    "1. Type of Dependent Variable\n",
    "\n",
    "   Linear Regression: Continuous outcome (for example, income, temperature).\n",
    "   Logistic Regression: Categorical (usually binary) outcome.\n",
    "\n",
    "2. Output\n",
    "\n",
    "   Linear Regression: Produces a numeric value.\n",
    "   Logistic Regression: Produces a probability between 0 and 1.\n",
    "\n",
    "3. Model Form\n",
    "\n",
    "   Linear Regression: Fits a straight line.\n",
    "   Logistic Regression: Uses an S-shaped (sigmoid) curve to model probabilities.\n",
    "\n",
    "4. Estimation Method\n",
    "\n",
    "   Linear Regression: Uses the method of least squares.\n",
    "   Logistic Regression: Uses maximum likelihood estimation.\n",
    "\n",
    "5. Interpretation\n",
    "\n",
    "   Linear Regression: Coefficients represent change in Y for a one-unit change in X.\n",
    "   Logistic Regression: Coefficients represent change in log-odds of the outcome.\n",
    "\n",
    "Thus, linear regression is used for predicting continuous values, whereas logistic regression is primarily used for classification problems involving categorical outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcf523f-6b21-45d5-aa15-f15c8d0bc823",
   "metadata": {},
   "source": [
    "#7.Three common evaluation metrics for regression models are:\n",
    "\n",
    "1. Mean Absolute Error (MAE)\n",
    "\n",
    "    MAE measures the average of the absolute differences between the actual values and the predicted values.\n",
    "    It tells us, on average, how much the predictions deviate from the true values, without considering direction.\n",
    "    Formula:\n",
    "     MAE = (1/n) ∑ |Yᵢ − Ŷᵢ|\n",
    "    It is easy to interpret because it is expressed in the same units as the dependent variable.\n",
    "\n",
    "2. Mean Squared Error (MSE)\n",
    "\n",
    "   MSE measures the average of the squared differences between actual and predicted values.\n",
    "   Squaring the errors penalizes larger errors more heavily than smaller ones.\n",
    "   Formula:\n",
    "     MSE = (1/n) ∑ (Yᵢ − Ŷᵢ)²\n",
    "   It is useful when large errors are particularly undesirable.\n",
    "\n",
    "3. R-squared (R²)\n",
    "\n",
    "   R² measures the proportion of variance in the dependent variable that is explained by the model.\n",
    "   It ranges from 0 to 1.\n",
    "   A higher R² indicates that the model explains a greater portion of the variability in the data.\n",
    "   It provides an overall measure of goodness of fit.\n",
    "\n",
    "These metrics help assess prediction accuracy and model performance from different perspectives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28321bf9-ac1d-43b8-aaaa-b5537c60bb9b",
   "metadata": {},
   "source": [
    "#8.The purpose of the R-squared (R²) metric in regression analysis is to measure how well the regression model explains the variability in the dependent variable.\n",
    "\n",
    "R-squared represents the proportion of the total variation in the dependent variable (Y) that is explained by the independent variable(s) included in the model.\n",
    "\n",
    "It is calculated as:\n",
    "\n",
    "R² = Explained Variation / Total Variation\n",
    "\n",
    "Its value ranges between 0 and 1.\n",
    "\n",
    "* R² = 0 indicates that the model does not explain any of the variability in the dependent variable.\n",
    "* R² = 1 indicates that the model perfectly explains all the variability in the dependent variable.\n",
    "\n",
    "For example, if R² = 0.85, this means that 85% of the variation in the dependent variable is explained by the regression model, while the remaining 15% is due to other factors or random error.\n",
    "\n",
    "Thus, the primary purpose of R-squared is to evaluate the goodness of fit of a regression model and to assess how well the model captures the underlying relationship between variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa1ba11-fde0-40f8-aeb3-415446618f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope (Coefficient): 0.6000000000000002\n",
      "Intercept: 2.1999999999999993\n"
     ]
    }
   ],
   "source": [
    "#9. SLR code in python\n",
    "\n",
    "# Import required libraries\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sample data (Independent variable X and Dependent variable y)\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "y = np.array([2, 4, 5, 4, 5])\n",
    "\n",
    "# Create and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Print slope (coefficient) and intercept\n",
    "print(\"Slope (Coefficient):\", model.coef_[0])\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214032a2-82cc-41f5-a968-0e1bff302fe0",
   "metadata": {},
   "source": [
    "#10.In a Simple Linear Regression model:\n",
    "\n",
    "Y = β₀ + β₁X\n",
    "\n",
    "the coefficients β₀ (intercept) and β₁ (slope) have specific interpretations.\n",
    "\n",
    "1. Intercept (β₀)\n",
    "\n",
    "   The intercept represents the expected value of the dependent variable (Y) when the independent variable (X) is equal to zero.\n",
    "\n",
    "   In practical terms, it is the baseline or starting value of Y before the effect of X is considered.\n",
    "\n",
    "   Example:\n",
    "   If we model exam marks based on study hours and the intercept is 40, this means that when study hours are zero, the predicted exam score is 40 marks (assuming the model is valid in that range).\n",
    "\n",
    "2. Slope (β₁)\n",
    "\n",
    "   The slope coefficient represents the expected change in the dependent variable (Y) for a one-unit increase in the independent variable (X), holding all else constant.\n",
    "\n",
    "   It indicates both the direction and magnitude of the relationship:\n",
    "\n",
    "   If β₁ is positive, Y increases as X increases.\n",
    "   If β₁ is negative, Y decreases as X increases.\n",
    "\n",
    "   Example:\n",
    "   If β₁ = 5 in the exam example, it means that for every additional hour of study, the predicted exam score increases by 5 marks.\n",
    "\n",
    "Thus, in simple linear regression, the intercept provides the baseline level of the dependent variable, while the slope quantifies the effect of the independent variable on the dependent variable.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
